import streamlit as st
import tensorflow as tf
from PIL import Image
import numpy as np
import cv2
import os
import logging
import pickle

# Configurar logging para suprimir warnings innecesarios
logging.getLogger('tensorflow').setLevel(logging.ERROR)
tf.get_logger().setLevel('ERROR')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Analizador de Rayos X - DenseNet121",
    page_icon="üè•",
    layout="wide"
)

# Configurar TensorFlow para usar el modo eager
tf.config.run_functions_eagerly(True)

# T√≠tulo y descripci√≥n
st.title("üè• Analizador de Rayos X para Detecci√≥n de Enfermedades")
st.markdown("""
Esta aplicaci√≥n utiliza un modelo DenseNet121 entrenado para detectar m√∫ltiples enfermedades en im√°genes de rayos X de t√≥rax.
Por favor, sube una imagen de rayos X en formato JPG o PNG.

**Enfermedades que puede detectar:**
- Infiltration, Effusion, Atelectasis, Nodule, Mass
""")

def preprocess_image(image, target_size=(224, 224)):
    """
    Preprocesa una imagen para el modelo DenseNet121 - EXACTAMENTE igual que en el notebook
    """
    try:
        # Convertir la imagen PIL a array numpy
        img_array = np.array(image)
        
        # Convertir a escala de grises si es necesario
        if len(img_array.shape) == 3:
            if img_array.shape[2] == 4:  # RGBA
                # Convertir RGBA a RGB primero
                img_array = img_array[:, :, :3]
            # Convertir RGB a escala de grises
            img = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        elif len(img_array.shape) == 2:
            img = img_array
        else:
            raise ValueError("Formato de imagen no soportado")

        # Verificar que la imagen no est√© vac√≠a
        if img.size == 0:
            raise ValueError("Imagen vac√≠a")

        # Asegurar que la imagen est√© en el rango correcto
        if img.dtype != np.uint8:
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)
            else:
                img = np.clip(img, 0, 255).astype(np.uint8)

        # Verificar dimensiones m√≠nimas
        if img.shape[0] < 32 or img.shape[1] < 32:
            raise ValueError(f"Imagen demasiado peque√±a: {img.shape}")

        # Aplicar CLAHE para mejorar el contraste
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        img = clahe.apply(img)

        # Redimensionar
        img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)

        # Convertir a RGB (DenseNet espera 3 canales)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)

        # Normalizar a float32 en rango [0, 1]
        img_normalized = img_rgb.astype(np.float32) / 255.0

        # Aplicar normalizaci√≥n de ImageNet
        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
        std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
        img_final = (img_normalized - mean) / std

        # Verificar que no hay valores NaN o infinitos
        if np.any(np.isnan(img_final)) or np.any(np.isinf(img_final)):
            raise ValueError("Valores inv√°lidos en la imagen procesada")

        # Agregar dimensi√≥n de batch
        img_final = np.expand_dims(img_final, axis=0)
        
        return img_final

    except Exception as e:
        st.error(f"Error en preprocesamiento: {str(e)}")
        return None

@st.cache_resource
def load_model():
    """
    Carga el modelo y las clases con cache de Streamlit
    """
    try:
        model_path = 'modelo_rayos_x.keras'
        mlb_path = 'mlb_classes.pkl'
        
        # Verificar que los archivos existen
        if not os.path.exists(model_path):
            st.error(f"""
            ‚ùå No se encontr√≥ el modelo entrenado: {model_path}
            
            Por favor aseg√∫rate de:
            1. Haber entrenado el modelo ejecutando el notebook
            2. Tener el archivo modelo_rayos_x.keras en el directorio actual
            """)
            return None
            
        if not os.path.exists(mlb_path):
            st.error(f"""
            ‚ùå No se encontr√≥ el archivo de clases: {mlb_path}
            
            Este archivo se genera durante el entrenamiento del modelo.
            """)
            return None

        with st.spinner("Cargando modelo..."):
            # Cargar el modelo
            model = tf.keras.models.load_model(model_path, compile=False)
            
            # Cargar el MultiLabelBinarizer
            with open(mlb_path, 'rb') as f:
                mlb = pickle.load(f)
            
            class_names = mlb.classes_
            
            # Recompilar el modelo
            model.compile(
                optimizer=tf.keras.optimizers.AdamW(learning_rate=0.0001),
                loss='binary_crossentropy',
                metrics=[
                    'accuracy',
                    tf.keras.metrics.AUC(name='auc'),
                    tf.keras.metrics.Precision(name='precision'),
                    tf.keras.metrics.Recall(name='recall'),
                    tf.keras.metrics.F1Score(name='f1_score', threshold=0.5)
                ]
            )
            
            # Validar la forma de entrada
            expected_shape = (None, 224, 224, 3)
            actual_shape = model.input_shape
            
            if actual_shape[1:] != expected_shape[1:]:
                st.warning(f"""
                ‚ö†Ô∏è Advertencia: La forma de entrada del modelo {actual_shape} 
                no coincide exactamente con la esperada {expected_shape}
                """)
            
            st.success(f"‚úÖ Modelo cargado exitosamente con {len(class_names)} clases")
            
            return model, mlb, class_names
    
    except Exception as e:
        st.error(f"‚ùå Error al cargar el modelo: {str(e)}")
        return None

def predict_disease(model_data, image, threshold=0.5):
    """
    Realiza predicciones de enfermedades usando el modelo
    """
    if model_data is None:
        return "‚ùå Modelo no disponible"
        
    model, mlb, class_names = model_data
    
    try:
        # Hacer la predicci√≥n
        predictions = model.predict(image, verbose=0)[0]
        
        # Obtener las enfermedades detectadas
        detected_diseases = []
        all_predictions = []
        
        for pred, class_name in zip(predictions, class_names):
            all_predictions.append((class_name, pred))
            if pred >= threshold:
                detected_diseases.append((class_name, pred))
        
        # Ordenar por confianza
        detected_diseases.sort(key=lambda x: x[1], reverse=True)
        all_predictions.sort(key=lambda x: x[1], reverse=True)
        
        # Crear el resultado detallado
        result = "## üìä Resultados del An√°lisis\n\n"
        
        if detected_diseases:
            result += f"### ‚úÖ Enfermedades Detectadas (umbral ‚â• {threshold:.1%}):\n"
            for disease, confidence in detected_diseases:
                confidence_emoji = "üî¥" if confidence >= 0.8 else "üü°" if confidence >= 0.6 else "üü†"
                result += f"{confidence_emoji} **{disease}**: {confidence:.1%}\n"
            
            # Clasificar por nivel de confianza
            high_conf = [d for d, c in detected_diseases if c >= 0.8]
            medium_conf = [d for d, c in detected_diseases if 0.6 <= c < 0.8]
            low_conf = [d for d, c in detected_diseases if c < 0.6]
            
            result += "\n### üìà Interpretaci√≥n:\n"
            if high_conf:
                result += f"üî¥ **Alta confianza**: {', '.join(high_conf)}\n"
            if medium_conf:
                result += f"üü° **Confianza media**: {', '.join(medium_conf)}\n"
            if low_conf:
                result += f"üü† **Baja confianza**: {', '.join(low_conf)}\n"
                
        else:
            result += f"### ‚úÖ No se detectaron enfermedades con confianza ‚â• {threshold:.1%}\n"
            result += "La imagen parece normal seg√∫n el an√°lisis del modelo.\n"
        
        # Mostrar top 5 predicciones independientemente del umbral
        result += "\n### üìã Top 5 Predicciones (todas las probabilidades):\n"
        for i, (disease, confidence) in enumerate(all_predictions[:5], 1):
            result += f"{i}. {disease}: {confidence:.1%}\n"
        
        # A√±adir disclaimers importantes
        result += "\n---\n"
        result += "### ‚ö†Ô∏è **IMPORTANTE - Limitaciones y Disclaimers:**\n"
        result += "- ü©∫ **Este an√°lisis NO reemplaza el diagn√≥stico m√©dico profesional**\n"
        result += "- üìä Las predicciones se basan en patrones aprendidos de datos hist√≥ricos\n"
        result += "- üéØ La precisi√≥n puede variar seg√∫n la calidad de la imagen\n"
        result += "- üë®‚Äç‚öïÔ∏è **Siempre consulte con un radi√≥logo o m√©dico calificado**\n"
        result += "- üîÑ Considere obtener una segunda opini√≥n para casos complejos\n"
        
        return result
        
    except Exception as e:
        return f"‚ùå Error durante la predicci√≥n: {str(e)}"

def display_model_info(model_data):
    """
    Muestra informaci√≥n sobre el modelo cargado
    """
    if model_data is None:
        return
        
    model, mlb, class_names = model_data
    
    with st.expander("‚ÑπÔ∏è Informaci√≥n del Modelo"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Arquitectura:** DenseNet121 pre-entrenado")
            st.write(f"**Par√°metros totales:** {model.count_params():,}")
            st.write(f"**Forma de entrada:** {model.input_shape}")
            st.write(f"**N√∫mero de clases:** {len(class_names)}")
        
        with col2:
            st.write("**Clases detectables:**")
            for i, class_name in enumerate(class_names, 1):
                st.write(f"{i}. {class_name}")

# Interfaz principal
def main():
    # Cargar el modelo
    model_data = load_model()
    
    if model_data is not None:
        display_model_info(model_data)
    
    # Widget para subir archivo
    uploaded_file = st.file_uploader(
        "üìÅ Sube una imagen de rayos X", 
        type=["jpg", "jpeg", "png"],
        help="Formatos soportados: JPG, JPEG, PNG. Tama√±o recomendado: al menos 224x224 p√≠xeles"
    )
    
    if uploaded_file is not None:
        # Mostrar la imagen original
        image = Image.open(uploaded_file)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("üì∑ Imagen Original")
            st.image(image, caption=f"Archivo: {uploaded_file.name}", use_container_width=True)
            
            # Informaci√≥n de la imagen
            st.write(f"**Dimensiones:** {image.size[0]} x {image.size[1]} p√≠xeles")
            st.write(f"**Modo:** {image.mode}")
            st.write(f"**Tama√±o del archivo:** {len(uploaded_file.getvalue()) / 1024:.1f} KB")
        
        with col2:
            st.subheader("‚öôÔ∏è Configuraci√≥n del An√°lisis")
            
            # Slider para ajustar el umbral de detecci√≥n
            threshold = st.slider(
                "üéØ Umbral de detecci√≥n",
                min_value=0.1,
                max_value=0.9,
                value=0.5,
                step=0.05,
                help="Ajusta el umbral de confianza. Valores m√°s altos = detecciones m√°s precisas pero menos sensibles."
            )
            
            # Mostrar interpretaci√≥n del umbral
            if threshold >= 0.8:
                st.info("üî¥ Umbral alto: Solo detecciones muy confiables")
            elif threshold >= 0.6:
                st.info("üü° Umbral medio: Balance entre precisi√≥n y sensibilidad")
            else:
                st.info("üü† Umbral bajo: M√°s sensible, puede incluir falsos positivos")
        
        # Bot√≥n para procesar la imagen
        if st.button("üîç Analizar Imagen", type="primary", use_container_width=True):
            if model_data is None:
                st.error("‚ùå No se puede analizar: modelo no disponible")
                return
            
            with st.spinner("üîÑ Analizando la imagen... Esto puede tomar unos momentos."):
                # Preprocesar la imagen
                processed_image = preprocess_image(image)
                
                if processed_image is not None:
                    # Hacer la predicci√≥n
                    prediction = predict_disease(model_data, processed_image, threshold)
                    st.markdown(prediction)
                else:
                    st.error("‚ùå Error al procesar la imagen. Por favor, intenta con otra imagen.")

# Sidebar con informaci√≥n adicional
def sidebar_info():
    st.sidebar.title("üìã Gu√≠a de Uso")
    st.sidebar.markdown("""
    ### üöÄ Pasos para usar la aplicaci√≥n:
    
    1. **üìÅ Sube una imagen** de rayos X de t√≥rax
    2. **‚öôÔ∏è Ajusta el umbral** seg√∫n tus necesidades
    3. **üîç Presiona "Analizar"** y espera los resultados
    4. **üìä Revisa las predicciones** y probabilidades
    
    ### üìè Recomendaciones de imagen:
    - **Formato:** JPG, JPEG, PNG
    - **Tama√±o:** M√≠nimo 224x224 p√≠xeles
    - **Calidad:** Imagen clara y bien contrastada
    - **Orientaci√≥n:** Rayos X de t√≥rax frontal (PA)
    
    ### üéØ Interpretaci√≥n de umbrales:
    - **0.1-0.4:** Muy sensible (muchos resultados)
    - **0.5-0.7:** Equilibrado (recomendado)
    - **0.8-0.9:** Muy espec√≠fico (solo alta confianza)
    """)
    
    st.sidebar.title("‚ö†Ô∏è Advertencias M√©dicas")
    st.sidebar.warning("""
    **IMPORTANTE:**
    
    - Esta herramienta es solo de apoyo
    - NO reemplaza el diagn√≥stico m√©dico
    - Siempre consulte con un profesional
    - Los resultados pueden contener errores
    - Use solo como referencia preliminar
    """)
    
    st.sidebar.title("üîß Informaci√≥n T√©cnica")
    st.sidebar.info("""
    **Modelo:** DenseNet121 pre-entrenado
    
    **Dataset:** NIH Chest X-ray Dataset
    
    **Precisi√≥n:** Variable seg√∫n la enfermedad
    
    **√öltima actualizaci√≥n:** Modelo mejorado
    """)

if __name__ == "__main__":
    sidebar_info()
    main() 